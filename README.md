# SPINRec - Stochastic Path Integration for Neural Recommender Explanations

The SPINRec method (stochastic path integration for neural recommender explanations) is a model-agnostic, post-hoc approach designed to explain the reasoning behind recommendations generated by recommender systems. By integrating along a path from a baseline to the input user vector, SPINRec generates an explanation map that illustrates each aspect of the user data's contribution to the recommendation output.
SPINRec innovates by incorporating a stochastic baseline sampling technique, enhancing its robustness and accuracy. In SPINRec, the baseline is modeled as a random tensor subjected to multiple sampling iterations.  This process yields a comprehensive set of explanations, enabling the selection of the most effective explanation with respect to specific metrics. 
Utilizing several counterfactual evaluation metrics, our results demonstrate the method's capability to provide insightful counterfactual explanations for various recommendation algorithms across different datasets.

## The idea of SPINRec
![SPINRec_diagram](https://github.com/ExplainRec/PI4Rec/blob/main/SPINRec_diagram.PNG)

## Repository

This repository hosts the code for the SPINRec framework. 
It was evaluated using three publicly available benchmarks: MovieLens1M, a subset of the Yahoo!Music dataset, and a subset of the Pinterest dataset. 
The evaluation employed three different recommenders: Multi Layer Perceptron (MLP), Variational Auto Encoder (VAE), and Neural Collaborative Filtering (NCF). 
Hyperparameter optimization was conducted using Optuna.

## Folders

* **processed_data**: contains three subfolders, one for each dataset. In each dataset folder lies the raw data files.
* **code**: contains several code notebooks:
  - data_processing - code related to the preprocessing step for preparing the raw data to run with our models.
  - recommenders_architecture - specifies the architecture of the recommenders that were used in the paper.
  - recommenders_training - contains code related to MLP, VAE and NCF recommenders training.
  - help_functions - includes the framework's functions that are being used in all notebooks.
  - SPINRec_functions - includes the SPINRec method related functions that are being used in the metrics notebooks.
  - baselines_functions - contains code related to the basleines implementation.
  - mertics_ABLT - contains code related to ablated SPINRec (zeroes as base) evaluation.
  - metrics_SPINRec - contains code related to the SPINRec evaluation.
  - metrics_baselines - contains code related to baselines evaluation.
  - Shap folder - contains notebooks with the implementation of SHAP baseline for all recommenders 

* **checkpoints**: Presently, this folder is empty.  It is the designated location for saving and loading the trained recommender's checkpoints. The checkpoints developed during our project are stored in the 'checkpoints' folder in the attached [drive](https://drive.google.com/drive/u/1/folders/1oto5QPrhisx2A4MCwub5OUHYdZTYAQxq).
  
## Requirements

* python 3.7.13
* Pytorch 1.12.1
* Pandas version: 1.3.5
* NumPy version: 1.21.6
* SHAP version: 0.42.1
* wandb 0.16.3 (the package we used for monitoring the recommenders training process)

## Usage

To use this code, follow these steps:
+ Create data to work with by running the data_processing notebooks.
  - Or in order to reproduce results from the paper without running the data_processing and SHAP notebooks, please download all files from [here](https://drive.google.com/drive/u/1/folders/1oto5QPrhisx2A4MCwub5OUHYdZTYAQxq) from the relevant folder <dataset_name> to data_preprocessing folder according to the data set you wish to run on.
    * Note that the "static_test_data" files that we used to train our recommender systems are avaiable in the Google Drive folder as well.
+ On every notebook, please specify the "data_name" variable to be 'ML1M'/'Yahoo'/'Pinterest', and the "recommender_name" variable to be 'MLP'/'VAE'/'NCF'.
+ All baselines' results were calculated using the 'metrics_baselines' notebook, metrics for the SPINRec approach and its variant were calculated using the dedicated notebooks.


{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb6edbf-9b01-4019-ad10-17daeeb0a0ee",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb692ee5-4d24-4148-ae45-3243700d625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle\n",
    "import ipynb\n",
    "import importlib\n",
    "import shap\n",
    "\n",
    "from torch.nn import Softmax\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d17c3e-db36-4829-950d-f261715685b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"VAE\"\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir.parent, DP_DIR)\n",
    "checkpoints_path = Path(export_dir.parent, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3e519-24cf-4fc5-b05f-3e0a53c66bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}\n",
    "\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\"),}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f036b1f-d545-4426-9d9d-242808012f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9e302-c311-4beb-94f6-c6db1b63ee77",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import VAE recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a249c32-13e9-4324-97e4-3f4994a452e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff52e83-89bc-4085-8a6c-642f2104257a",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a0c36-a37b-47a6-bf9d-e1a996652df6",
   "metadata": {},
   "source": [
    "## VAE wrapper for shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109e029-c0fd-4cbc-9c10-2322dbd3bb45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WrapperModel(nn.Module):\n",
    "    def __init__(self, model, item_array, cluster_to_items, item_to_cluster, num_items, device, num_clusters=10):\n",
    "        super(WrapperModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.n_items = num_items\n",
    "        self.cluster_to_items = cluster_to_items\n",
    "        self.item_to_cluster = item_to_cluster\n",
    "        self.item_array = item_array\n",
    "        self.device = device\n",
    "        self.n_clusters = num_clusters\n",
    "\n",
    "    def forward(self, input_array):\n",
    "        batch_size = input_array.shape[0]\n",
    "        user_vector_batch = torch.zeros(batch_size, self.n_items).to(self.device)\n",
    "\n",
    "        for cluster in range(input_array.shape[1]):\n",
    "            cluster_indices = self.cluster_to_items[cluster]\n",
    "            user_vector_batch[:, cluster_indices] = torch.from_numpy(input_array[:, cluster]).unsqueeze(1).float().to(self.device)\n",
    "\n",
    "        model_output_batch = self.model(user_vector_batch)\n",
    "        softmax_output_batch = torch.softmax(model_output_batch, dim=-1)\n",
    "\n",
    "        user_cluster_scores = []\n",
    "        for user in range(batch_size):\n",
    "            user_cluster_scores_per_user = []\n",
    "            for cluster, items in self.cluster_to_items.items():\n",
    "                cluster_scores = softmax_output_batch[user, items]\n",
    "                avg_score = torch.mean(cluster_scores)\n",
    "                user_cluster_scores_per_user.append(avg_score.unsqueeze(0)) \n",
    "            user_cluster_scores.append(torch.cat(user_cluster_scores_per_user)) \n",
    "\n",
    "        return torch.stack(user_cluster_scores).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184b2eb-4b83-41f9-85ea-4ff05e51e174",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88175d0-d540-4ed4-8607-9fac7108b14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e230c-9e05-468c-8317-a53d333a0869",
   "metadata": {},
   "source": [
    "## Create / Load top recommended item dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d9763-d7cd-4320-afd5-0b06bddab70c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f)\n",
    "pop_array = np.zeros(len(pop_dict))\n",
    "for key, value in pop_dict.items():\n",
    "    pop_array[key] = value\n",
    "    \n",
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "\n",
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)\n",
    "\n",
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]\n",
    "\n",
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "           'num_features': num_items, \n",
    "            'demographic':False,\n",
    "          'pop_array':pop_array,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601bdd66-5efb-4695-8258-5c322a8c1ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VAE_config= {\n",
    "\"enc_dims\": [512,128],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}\n",
    "\n",
    "\n",
    "Pinterest_VAE_config= {\n",
    "\"enc_dims\": [256,64],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}\n",
    "\n",
    "def load_recommender():\n",
    "    if recommender_name=='MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name=='VAE':\n",
    "        if data_name == \"Pinterest\":\n",
    "            recommender = VAE(Pinterest_VAE_config, **kw_dict)\n",
    "        else:\n",
    "            recommender = VAE(VAE_config, **kw_dict)\n",
    "    elif recommender_name=='NCF':\n",
    "        MLP_temp = MLP_model(hidden_size=hidden_dim, num_layers=3, **kw_dict)\n",
    "        GMF_temp = GMF_model(hidden_size=hidden_dim, **kw_dict)\n",
    "        recommender = NCF(factor_num=hidden_dim, num_layers=3, dropout=0.5, model= 'NeuMF-pre', GMF_model= GMF_temp, MLP_model=MLP_temp, **kw_dict)\n",
    "    \n",
    "    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path))\n",
    "    recommender.load_state_dict(recommender_checkpoint)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad= False\n",
    "        \n",
    "    return recommender\n",
    "\n",
    "\n",
    "recommender = load_recommender()\n",
    "optimizer = torch.optim.Adam(recommender.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b50b9-ce3f-467e-8143-0b5fa960d82f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_dicts = True # True if it is the first time running the notebook for the specific recommender and data set\n",
    "if create_dicts:\n",
    "    top1_train = {}\n",
    "    top1_test = {}  \n",
    "    for i in range(train_array.shape[0]):\n",
    "        user_index = int(train_data.index[i])\n",
    "        user_tensor = torch.Tensor(train_array[i]).to(device)\n",
    "        top1_train[user_index] = int(get_user_recommended_item(user_tensor, recommender, **kw_dict))\n",
    "    for i in range(test_array.shape[0]):\n",
    "        user_index = int(test_data.index[i])\n",
    "        user_tensor = torch.Tensor(test_array[i]).to(device)\n",
    "        top1_test[user_index] = int(get_user_recommended_item(user_tensor, recommender, **kw_dict))\n",
    "        \n",
    "    with open(Path(files_path,f'top1_train_{data_name}_{recommender_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(top1_train, f)\n",
    "    with open(Path(files_path,f'top1_test_{data_name}_{recommender_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(top1_test, f)\n",
    "else:\n",
    "    with open(Path(files_path,f'top1_train_{data_name}_{recommender_name}.pkl'), 'rb') as f:\n",
    "        top1_train = pickle.load(f)\n",
    "    with open(Path(files_path,f'top1_test_{data_name}_{recommender_name}.pkl'), 'rb') as f:\n",
    "        top1_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f932393-f7c0-41ad-b651-d67969055b5b",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99068cb0-964d-487e-a868-cd087283f401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 100\n",
    "u_train = torch.tensor(train_array).float()\n",
    "v_train = all_items_tensor\n",
    "user_ids = np.arange(train_array.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19ef80-9420-460a-add1-37701f7681c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "# Cluster items using k-means\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "k = 10\n",
    "\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "clusters = kmeans.fit_predict(np.transpose(u_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83450799-723c-4702-96df-e6bac066d669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_clusters = kmeans.predict(np.transpose(u_train))\n",
    "\n",
    "# Create mapping from items to clusters\n",
    "item_to_cluster = {}\n",
    "# Create mapping from clusters to items\n",
    "cluster_to_items = {}\n",
    "for i, cluster in enumerate(item_clusters):\n",
    "    item_to_cluster[i] = cluster\n",
    "    if(cluster not in cluster_to_items.keys()):\n",
    "        cluster_to_items[cluster] = []\n",
    "    cluster_to_items[cluster].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25707482-0712-48c8-8a7d-51a072b97390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_test = torch.tensor(test_array).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a537ef-c86a-4a16-9421-47bfe6a669e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters = np.zeros((u_test.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0764fa-a2da-4d7f-8432-9c490796284c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters[:,i] = np.sum(u_test.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d147441-28cf-4fd5-b8d7-0cc108bc5ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_bin =  np.where(user_to_clusters > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224823cf-fb89-4867-bebb-c5110504ea5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_train = np.zeros((u_train.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281ef18-ebaf-473b-9019-0e944ea63cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_test = np.zeros((u_test.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a88e7-b961-4906-a4d3-68fa3634538b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_value = 0\n",
    "target_items_test = list(top1_test.values())\n",
    "target_items_train = list(top1_train.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdad198-bf47-4386-beaa-10ce7bb0affb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters_train[:,i] = np.sum(u_train.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a299d-0707-4e36-b80c-a46ca2931257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_train_bin = np.where(user_to_clusters_train > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dc706e-8f65-4e27-91a7-6de1965e2206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col2 = list(top1_train.values())\n",
    "input_train_array = np.insert(user_to_clusters_train_bin, 0, col2, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ace6c-3dfc-4f19-a2bf-b6c315070441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters_test[:,i] = np.sum(u_test.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bd361-4d4b-4cf5-95ba-152b6e23475e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_test_bin = np.where(user_to_clusters_test > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cc7f8-288d-48ee-8bca-d61c4c82288e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col2 = list(top1_test.values())\n",
    "input_test_array= np.insert(user_to_clusters_test_bin, 0, col2, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58106a-04d2-48c3-9ffd-268ac2e4b199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wrap_model = WrapperModel(recommender, items_array, cluster_to_items, item_to_cluster, num_items, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f4bb2-79ba-476b-a433-c58ed73ba0c5",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c9f9b-6da6-474c-bcde-06f863f2cdc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeabb5c-44f3-442d-b4da-42e117989ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_subset = shap.sample(user_to_clusters_train_bin, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd790e-2faa-40ce-8675-cbb7d62a5e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(wrap_model, sampled_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0d53d-1a7d-480c-8c1b-983e5f27d388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_values_test = explainer.shap_values(user_to_clusters_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944f1e3-ceac-4d73-afe8-5671dcac8f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_shap = np.mean(shap_values_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d7a56-7070-4e70-a417-2046af2f5349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col1 = np.arange(test_array.shape[0]) + train_array.shape[0]\n",
    "input_test_array = np.insert(average_shap, 0, col1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b302ae-f7b7-44e1-8650-0107bd13e1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(item_to_cluster, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af2cc0-3efa-4f74-9a88-7f89d6bf0fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'shap_values_{recommender_name}_{data_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(input_test_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11261787-fcd5-4030-b5fb-454af55affde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

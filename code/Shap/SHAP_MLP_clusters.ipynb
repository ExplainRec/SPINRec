{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab698be-c174-4dce-be71-b04e4ddd55cb",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb692ee5-4d24-4148-ae45-3243700d625e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from scipy import sparse\n",
    "from os import path\n",
    "import shap\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import ipynb\n",
    "import importlib\n",
    "import warnings\n",
    "\n",
    "from torch.nn import Softmax\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f17170-e23a-436a-bd15-1dcc4ed2ad5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"MLP\" \n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd()).parent\n",
    "files_path = Path(export_dir.parent, DP_DIR)\n",
    "checkpoints_path = Path(export_dir.parent, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b45429-e794-44ee-8258-0336a2b0f311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}\n",
    "\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\"),}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365e540-82e5-4fb3-b37e-f0525deca01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9e302-c311-4beb-94f6-c6db1b63ee77",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import MLP recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0bb54-4774-40b1-93cc-b2017dbaa87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a877ce5-57d7-4d0d-96d5-ab4d628411fb",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce9b6d1-4514-43e6-855b-c5461bb51b22",
   "metadata": {},
   "source": [
    "### MLP Wrapper for SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72b7a4-0439-48fa-8c20-38f74bb8d170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPWrapper(MLP):\n",
    "    def __init__(self, hidden_size, cluster_to_items, **kw):\n",
    "        super().__init__(hidden_size=hidden_size, device=device, num_items=num_items)\n",
    "        self.cluster_to_items = cluster_to_items\n",
    "        self.items_array = items_array\n",
    "        self.device = device\n",
    "        self.num_items = num_items\n",
    "        \n",
    "    def preprocess(self, batch):\n",
    "        items = batch[:, 0]\n",
    "        clusters = batch[:, 1:]\n",
    "        n_clusters = clusters.shape[1]\n",
    "\n",
    "        items_tensor = torch.Tensor(self.items_array[items]).to(self.device)\n",
    "        user_tensor = torch.zeros((len(batch), self.num_items), dtype=torch.float).to(self.device)\n",
    "\n",
    "        for cluster in range(n_clusters):\n",
    "            cluster_indices = torch.tensor(clusters[:, cluster], dtype=torch.float).to(self.device)\n",
    "            user_tensor[:, self.cluster_to_items[cluster]] = cluster_indices.unsqueeze(1)\n",
    "\n",
    "        return user_tensor, items_tensor\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch_size = 256  \n",
    "        outputs = []\n",
    "        for i in range(0, len(batch), batch_size):\n",
    "            mini_batch = batch[i:i+batch_size]\n",
    "            user_tensor, items_tensor = self.preprocess(mini_batch)\n",
    "            output = super().forward(user_tensor, items_tensor)\n",
    "            outputs.append(torch.diag(output).detach().cpu().numpy())\n",
    "        return np.concatenate(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184b2eb-4b83-41f9-85ea-4ff05e51e174",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88175d0-d540-4ed4-8607-9fac7108b14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea2155-6e2c-4e2f-8f25-605172406db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#users' ids in the test dataset\n",
    "row_test_indices = np.arange(test_array.shape[0]) + train_array.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cf681-0146-45ac-bb9f-d2a7030de49f",
   "metadata": {},
   "source": [
    "## Create / Load top recommended item dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f59ad4-0b87-49db-aa57-51979c85a820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f)\n",
    "pop_array = np.zeros(len(pop_dict))\n",
    "for key, value in pop_dict.items():\n",
    "    pop_array[key] = value\n",
    "\n",
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "\n",
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)\n",
    "\n",
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]\n",
    "\n",
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "           'num_features': num_items, \n",
    "            'demographic':False,\n",
    "          'pop_array':pop_array,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f8dea-2107-48ac-b814-bcafbbf64183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_recommender():\n",
    "    if recommender_name=='MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name=='VAE':\n",
    "        if data_name == \"Pinterest\":\n",
    "            recommender = VAE(Pinterest_VAE_config, **kw_dict)\n",
    "        else:\n",
    "            recommender = VAE(VAE_config, **kw_dict)\n",
    "    elif recommender_name=='NCF':\n",
    "        MLP_temp = MLP_model(hidden_size=hidden_dim, num_layers=3, **kw_dict)\n",
    "        GMF_temp = GMF_model(hidden_size=hidden_dim, **kw_dict)\n",
    "        recommender = NCF(factor_num=hidden_dim, num_layers=3, dropout=0.5, model= 'NeuMF-pre', GMF_model= GMF_temp, MLP_model=MLP_temp, **kw_dict)\n",
    "    \n",
    "    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path))\n",
    "    recommender.load_state_dict(recommender_checkpoint)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad= False\n",
    "        \n",
    "    return recommender\n",
    "\n",
    "\n",
    "recommender = load_recommender()\n",
    "optimizer = torch.optim.Adam(recommender.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7adff-5112-4c3b-afa8-a929fa63b7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_dicts = True # True if it is the first time running the notebook for the specific recommender and data set\n",
    "\n",
    "if create_dicts:\n",
    "    top1_train = {}\n",
    "    top1_test = {}  \n",
    "    for i in range(train_array.shape[0]):\n",
    "        user_index = int(train_data.index[i])\n",
    "        user_tensor = torch.Tensor(train_array[i]).to(device)\n",
    "        top1_train[user_index] = int(get_user_recommended_item(user_tensor, recommender, **kw_dict))\n",
    "    for i in range(test_array.shape[0]):\n",
    "        user_index = int(test_data.index[i])\n",
    "        user_tensor = torch.Tensor(test_array[i]).to(device)\n",
    "        top1_test[user_index] = int(get_user_recommended_item(user_tensor, recommender, **kw_dict))\n",
    "        \n",
    "    with open(Path(files_path,f'top1_train_{data_name}_{recommender_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(top1_train, f)\n",
    "    with open(Path(files_path,f'top1_test_{data_name}_{recommender_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(top1_test, f)\n",
    "else:\n",
    "    with open(Path(files_path,f'top1_train_{data_name}_{recommender_name}.pkl'), 'rb') as f:\n",
    "        top1_train = pickle.load(f)\n",
    "    with open(Path(files_path,f'top1_test_{data_name}_{recommender_name}.pkl'), 'rb') as f:\n",
    "        top1_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f932393-f7c0-41ad-b651-d67969055b5b",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99068cb0-964d-487e-a868-cd087283f401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 100\n",
    "u_train = torch.tensor(train_array).float()\n",
    "v_train = all_items_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19ef80-9420-460a-add1-37701f7681c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "# Cluster items using k-means\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "k = 10\n",
    "\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "clusters = kmeans.fit_predict(np.transpose(u_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83450799-723c-4702-96df-e6bac066d669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_clusters = kmeans.predict(np.transpose(u_train))\n",
    "\n",
    "# Create mapping from items to clusters\n",
    "item_to_cluster = {}\n",
    "# Create mapping from clusters to items\n",
    "cluster_to_items = {}\n",
    "for i, cluster in enumerate(item_clusters):\n",
    "    item_to_cluster[i] = cluster\n",
    "    if(cluster not in cluster_to_items.keys()):\n",
    "        cluster_to_items[cluster] = []\n",
    "    cluster_to_items[cluster].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25707482-0712-48c8-8a7d-51a072b97390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_test = torch.tensor(test_array).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a537ef-c86a-4a16-9421-47bfe6a669e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters = np.zeros((u_test.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0764fa-a2da-4d7f-8432-9c490796284c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters[:,i] = np.sum(u_test.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d147441-28cf-4fd5-b8d7-0cc108bc5ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_bin =  np.where(user_to_clusters > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224823cf-fb89-4867-bebb-c5110504ea5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_train = np.zeros((u_train.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90150bd6-877f-4a52-9365-52e1c551193e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_test = np.zeros((u_test.shape[0],10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06cac5-84b2-42e3-9d56-da1d299ed383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_value = 0\n",
    "target_items_test = list(top1_test.values())\n",
    "target_items_train = list(top1_train.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce7352d-9099-4db1-bb4c-9a472419c76c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters_train[:,i] = np.sum(u_train.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc2b9a-15c2-4226-b2bd-7c34a1335964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_train_bin = np.where(user_to_clusters_train > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fe3f6-ee86-41d5-9150-43c2c15edb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col2 = list(top1_train.values())\n",
    "input_train_array = np.insert(user_to_clusters_train_bin, 0, col2, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdad198-bf47-4386-beaa-10ce7bb0affb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in cluster_to_items.keys():\n",
    "    user_to_clusters_test[:,i] = np.sum(u_test.cpu().detach().numpy().T[cluster_to_items[i]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a299d-0707-4e36-b80c-a46ca2931257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_to_clusters_test_bin = np.where(user_to_clusters_test > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a526e-b48b-4bcb-8d8a-2a2e450d144e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col2 = list(top1_test.values())\n",
    "input_test_array= np.insert(user_to_clusters_test_bin, 0, col2, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b85d4a-67c4-4172-a345-c36ed8e8acd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wrap_model =  MLPWrapper(hidden_dim, cluster_to_items, **kw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f4bb2-79ba-476b-a433-c58ed73ba0c5",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c9f9b-6da6-474c-bcde-06f863f2cdc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeabb5c-44f3-442d-b4da-42e117989ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_subset = shap.sample(input_train_array,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd790e-2faa-40ce-8675-cbb7d62a5e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(wrap_model, sampled_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0d53d-1a7d-480c-8c1b-983e5f27d388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shap_values_test = explainer.shap_values(input_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d278b-eaf2-4b45-8e3d-b08fa2765afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col1 = row_test_indices\n",
    "input_test_array = np.insert(shap_values_test[:, 1:], 0, col1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b302ae-f7b7-44e1-8650-0107bd13e1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(item_to_cluster, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af2cc0-3efa-4f74-9a88-7f89d6bf0fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path,f'shap_values_{recommender_name}_{data_name}.pkl'), 'wb') as f:\n",
    "    pickle.dump(input_test_array, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

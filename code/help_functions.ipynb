{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e035cd6",
   "metadata": {},
   "source": [
    "### This notebook includes the framework's functions that are being used in all notebooks.\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5f6cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6255d17",
   "metadata": {},
   "source": [
    "# Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57327551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that samples different train data variation for a diverse training\n",
    "def sample_indices(data, **kw):\n",
    "    num_items = kw['num_items']\n",
    "    pop_array = kw['pop_array']\n",
    "    \n",
    "    matrix = np.array(data)[:,:num_items] # keep only items columns, remove demographic features columns\n",
    "    zero_indices = []\n",
    "    one_indices = []\n",
    "\n",
    "    for row in matrix:\n",
    "        zero_idx = np.where(row == 0)[0]\n",
    "        one_idx = np.where(row == 1)[0]\n",
    "        probs = pop_array[zero_idx]\n",
    "        probs = probs/ np.sum(probs)\n",
    "\n",
    "        sampled_zero = np.random.choice(zero_idx, p = probs) # sample negative interactions according to items popularity \n",
    "        zero_indices.append(sampled_zero)\n",
    "\n",
    "        sampled_one = np.random.choice(one_idx) # sample positive interactions from user's history\n",
    "        data.iloc[row, sampled_one] = 0\n",
    "        one_indices.append(sampled_one)\n",
    "\n",
    "    data['pos'] = one_indices\n",
    "    data['neg'] = zero_indices\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that returns a specific item's rank in user's recommendations list\n",
    "def get_index_in_the_list(user_tensor, original_user_tensor, item_id, recommender, **kw):\n",
    "    top_k_list = list(get_top_k(user_tensor, original_user_tensor, recommender, **kw).keys())\n",
    "    return top_k_list.index(item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fbbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary of items and recommendations scores for a specific user\n",
    "def get_top_k(user_tensor, original_user_tensor, model, **kw):\n",
    "    all_items_tensor = kw['all_items_tensor']\n",
    "    num_items = kw['num_items']\n",
    "    \n",
    "    item_prob_dict = {}\n",
    "    output_model = [float(i) for i in recommender_run(user_tensor, model, all_items_tensor, None, 'vector', **kw).cpu().detach().numpy()]\n",
    "    original_user_vector = np.array(original_user_tensor.cpu())[:num_items]\n",
    "    catalog = np.ones_like(original_user_vector)- original_user_vector\n",
    "    output = catalog*output_model\n",
    "    for i in range(len(output)):\n",
    "        if catalog[i] > 0:\n",
    "            item_prob_dict[i]=output[i]\n",
    "    sorted_items_by_prob  = sorted(item_prob_dict.items(), key=lambda item: item[1],reverse=True)\n",
    "    return dict(sorted_items_by_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that wraps the different recommenders types \n",
    "# returns user's scores with respect to a certain item or for all items \n",
    "def recommender_run(user_tensor, recommender, item_tensor = None, item_id= None, wanted_output = 'single', **kw):\n",
    "    output_type=kw['output_type']\n",
    "    if output_type == 'single':\n",
    "        if wanted_output == 'single':\n",
    "            return recommender(user_tensor, item_tensor)\n",
    "        else:\n",
    "            return recommender(user_tensor, item_tensor).squeeze()\n",
    "    else:\n",
    "        if wanted_output == 'single':\n",
    "            return recommender(user_tensor).squeeze()[item_id]\n",
    "        else:\n",
    "            return recommender(user_tensor).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate recommenders on test set and return HR@10, HR@50, HR@100, MRR and MPR\n",
    "def recommender_evaluations(recommender, **kw):\n",
    "    static_test_data = kw['static_test_data'].copy()\n",
    "    device = kw['device']\n",
    "    items_array = kw['items_array']\n",
    "    num_items = kw['num_items']\n",
    "\n",
    "    counter_10 = 0\n",
    "    counter_50 = 0\n",
    "    counter_100 = 0\n",
    "    RR = 0\n",
    "    PR = 0\n",
    "    temp_test_array = np.array(static_test_data)\n",
    "    n = temp_test_array.shape[0]\n",
    "    for i in range(n):\n",
    "        item_id = temp_test_array[i][-2]\n",
    "        item_tensor = items_array[item_id]\n",
    "        user_tensor = torch.Tensor(temp_test_array[i][:-2]).to(device)\n",
    "        user_tensor[item_id]=0\n",
    "        index = get_index_in_the_list(user_tensor, user_tensor, item_id, recommender, **kw) +1 \n",
    "        if index <= 10:\n",
    "            counter_10 +=1 \n",
    "        if index <= 50:\n",
    "            counter_50 +=1 \n",
    "        if index <= 100:\n",
    "            counter_100 +=1             \n",
    "        RR += np.reciprocal(index)\n",
    "        PR += index/num_items\n",
    "        \n",
    "    return counter_10/n, counter_50/n, counter_100/n,  RR/n, PR*100/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163acc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user's top recommended item\n",
    "def get_user_recommended_item(user_tensor, recommender, **kw):\n",
    "    all_items_tensor = kw['all_items_tensor']\n",
    "    num_items = kw['num_items']\n",
    "    user_res = recommender_run(user_tensor, recommender, all_items_tensor, None, 'vector', **kw)[:num_items]\n",
    "    user_tensor = user_tensor[:num_items]\n",
    "    user_catalog = torch.ones_like(user_tensor)-user_tensor\n",
    "    user_recommenations = torch.mul(user_res, user_catalog)\n",
    "    return(torch.argmax(user_recommenations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d782ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the ndcg score of the restored recommendations list after perturbating the user's data.\n",
    "def get_ndcg(ranked_list, target_item, **kw):\n",
    "    device = kw['device']\n",
    "    if target_item not in ranked_list:\n",
    "        return 0.0\n",
    "\n",
    "    target_idx = torch.tensor(ranked_list.index(target_item), device=device)\n",
    "    dcg = torch.reciprocal(torch.log2(target_idx + 2))\n",
    "\n",
    "    return dcg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c742a0-cc27-4b8e-8873-48664e2345f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c6c80-f73e-47c2-a47e-6b867a61b500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_recommender(data_name, hidden_dim, checkpoints_path, recommender_path, **kw_dict):\n",
    "    VAE_config= {\n",
    "    \"enc_dims\": [512,128],\n",
    "    \"dropout\": 0.5,\n",
    "    \"anneal_cap\": 0.2,\n",
    "    \"total_anneal_steps\": 200000}\n",
    "\n",
    "    Pinterest_VAE_config= {\n",
    "    \"enc_dims\": [256,64],\n",
    "    \"dropout\": 0.5,\n",
    "    \"anneal_cap\": 0.2,\n",
    "    \"total_anneal_steps\": 200000}\n",
    "\n",
    "    recommender_name = kw_dict['recommender_name']\n",
    "    \n",
    "    if recommender_name=='MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name=='VAE':\n",
    "        if data_name == \"Pinterest\":\n",
    "            recommender = VAE(Pinterest_VAE_config, **kw_dict)\n",
    "        else:\n",
    "            recommender = VAE(VAE_config, **kw_dict)\n",
    "    elif recommender_name=='NCF':\n",
    "        MLP_temp = MLP_model(hidden_size=hidden_dim, num_layers=3, **kw_dict)\n",
    "        GMF_temp = GMF_model(hidden_size=hidden_dim, **kw_dict)\n",
    "        recommender = NCF(factor_num=hidden_dim, num_layers=3, dropout=0.5, model= 'NeuMF-pre', GMF_model= GMF_temp, MLP_model=MLP_temp, **kw_dict)\n",
    "    \n",
    "    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path))\n",
    "    recommender.load_state_dict(recommender_checkpoint)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad= False\n",
    "        \n",
    "    return recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd001ce-bfeb-42db-a591-84dfb461d38c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metrics calculations (will be used in all metrics notebooks)\n",
    "def single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender_model, expl_dict, **kw_dict):\n",
    "    device = kw_dict['device']\n",
    "    \n",
    "    POS_masked = user_tensor\n",
    "    NEG_masked = user_tensor\n",
    "    POS_masked[item_id]=0\n",
    "    NEG_masked[item_id]=0\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "    \n",
    "    \n",
    "    bins=[0]+[len(x) for x in np.array_split(np.arange(user_hist_size), num_of_bins, axis=0)]\n",
    "    \n",
    "    POS_at_5 = [0]*(len(bins))\n",
    "    POS_at_10=[0]*(len(bins))\n",
    "    POS_at_20=[0]*(len(bins))\n",
    "    \n",
    "    DEL = [0]*(len(bins))\n",
    "    INS = [0]*(len(bins))\n",
    "    NDCG = [0]*(len(bins))\n",
    "\n",
    "    \n",
    "    POS_sim_items = expl_dict\n",
    "    NEG_sim_items  = list(sorted(dict(POS_sim_items).items(), key=lambda item: item[1],reverse=False))\n",
    "    \n",
    "    total_items=0\n",
    "    for i in range(len(bins)):\n",
    "        total_items += bins[i]\n",
    "            \n",
    "        POS_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        \n",
    "        for j in POS_sim_items[:total_items]:\n",
    "            POS_masked[j[0]] = 1\n",
    "        POS_masked = user_tensor - POS_masked # remove the masked items from the user history\n",
    "\n",
    "        NEG_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        for j in NEG_sim_items[:total_items]:\n",
    "            NEG_masked[j[0]] = 1\n",
    "        NEG_masked = user_tensor - NEG_masked # remove the masked items from the user history \n",
    "        \n",
    "        POS_ranked_list = get_top_k(POS_masked, user_tensor, recommender_model, **kw_dict)\n",
    "        \n",
    "        if item_id in list(POS_ranked_list.keys()):\n",
    "            POS_index = list(POS_ranked_list.keys()).index(item_id)+1\n",
    "        else:\n",
    "            POS_index = num_items\n",
    "        NEG_index = get_index_in_the_list(NEG_masked, user_tensor, item_id, recommender_model, **kw_dict)+1\n",
    "\n",
    "        # for pos:\n",
    "        POS_at_5[i] = 1 if POS_index <=5 else 0\n",
    "        POS_at_10[i] = 1 if POS_index <=10 else 0\n",
    "        POS_at_20[i] = 1 if POS_index <=20 else 0\n",
    "\n",
    "        # for del:\n",
    "        DEL[i] = float(recommender_run(POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\n",
    "\n",
    "        # for ins:\n",
    "        INS[i] = float(recommender_run(user_tensor-POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\n",
    "\n",
    "        #for NDCG:\n",
    "        NDCG[i]= get_ndcg(list(POS_ranked_list.keys()),item_id, **kw_dict)\n",
    "        \n",
    "    res = [DEL, INS, NDCG, POS_at_5, POS_at_10, POS_at_20]\n",
    "    for i in range(len(res)):\n",
    "        res[i] = np.array(res[i])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d8897d-aa7f-4cad-b2d3-8d45c4dcae8b",
   "metadata": {},
   "source": [
    "## LXR Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87ef82-d16a-4c78-afc3-e9f864255844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LXR_loss(nn.Module):\n",
    "    def __init__(self, lambda_pos, lambda_neg, alpha):\n",
    "        super(LXR_loss, self).__init__()\n",
    "        \n",
    "        self.lambda_pos = lambda_pos\n",
    "        self.lambda_neg = lambda_neg\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        \n",
    "    def forward(self, user_tensors, items_tensors, items_ids, pos_masks):\n",
    "        neg_masks = torch.sub(torch.ones_like(pos_masks), pos_masks)\n",
    "        x_masked_pos = user_tensors * pos_masks\n",
    "        x_masked_neg = user_tensors * neg_masks\n",
    "        if output_type=='single':\n",
    "            x_masked_res_pos = recommender_run(x_masked_pos, recommender, items_tensors, item_id=items_ids, wanted_output = 'single', **kw_dict)\n",
    "            x_masked_res_neg = recommender_run(x_masked_neg, recommender, items_tensors, item_id=items_ids, wanted_output = 'single', **kw_dict)\n",
    "        else:\n",
    "            x_masked_res_pos_before = recommender_run(x_masked_pos, recommender, items_tensors, item_id=items_ids, wanted_output = 'vector', **kw_dict)\n",
    "            x_masked_res_neg_before = recommender_run(x_masked_neg, recommender, items_tensors, item_id=items_ids, wanted_output = 'vector', **kw_dict)\n",
    "            rows=torch.arange(len(items_ids))\n",
    "            x_masked_res_pos = x_masked_res_pos_before[rows, items_ids] \n",
    "            x_masked_res_neg = x_masked_res_neg_before[rows, items_ids] \n",
    "        \n",
    "            \n",
    "        pos_loss = -torch.mean(torch.log(x_masked_res_pos))\n",
    "        neg_loss = torch.mean(torch.log(x_masked_res_neg))\n",
    "        l1 = x_masked_pos[x_masked_pos>0].mean()\n",
    "        combined_loss = self.lambda_pos*pos_loss + self.lambda_neg*neg_loss + self.alpha*l1\n",
    "        return combined_loss, pos_loss, neg_loss, l1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18831b05",
   "metadata": {},
   "source": [
    "### This notebook produces the metrics for a specific recommendation system and dataset for all the baselines.\n",
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160299a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import ipynb\n",
    "import importlib\n",
    "import sys\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03618690-e1d1-4b0e-9326-a3cd9d989f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "torch.cuda.set_per_process_memory_fraction(0.9, 0)  # This sets the fraction of GPU memory for PyTorch, you can adjust this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59163763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"MLP\" ### Can be MLP, VAE, NCF\n",
    "\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir.parent, DP_DIR)\n",
    "checkpoints_path = Path(export_dir.parent, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d72884-bb1b-435f-9be7-0be0e02820d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_file_name = \"NEW_FILE_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56467a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}\n",
    "\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\"),}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64,\n",
    "}\n",
    "\n",
    "LXR_checkpoint_dict = {\n",
    "    (\"ML1M\",\"VAE\"): ('LXR_ML1M_VAE_26_38_128_3.185652725834087_1.420642300151426.pt',128),\n",
    "    (\"ML1M\",\"MLP\"): ('LXR_ML1M_MLP_12_39_64_11.59908096547193_0.1414854294885049.pt',64),\n",
    "    (\"ML1M\",\"NCF\"): ('LXR_ML1M_NCF_17_38_64_14.950042796023537_0.1778309603009678.pt',64),\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): ('LXR_Yahoo_VAE_neg-1.5pos_combined_19_26_128_18.958765029913238_4.92235962483309.pt',128),\n",
    "    (\"Yahoo\",\"MLP\"):('LXR_Yahoo_MLP_neg-pos_combined_last_29_37_128_12.40692505393434_0.19367009952856118.pt',128),\n",
    "    (\"Yahoo\",\"NCF\"): ('LXR_Yahoo_NCF_neg-pos_combined_loss_14_14_32_16.01464392466348_6.880015038643981.pt', 32),\n",
    "\n",
    "    (\"Pinterest\",\"VAE\"): ('LXR_Pinterest_VAE_comb_4_27_32_6.3443735346179855_1.472868807603448.pt',32),\n",
    "    (\"Pinterest\",\"MLP\"): ('LXR_Pinterest_MLP_0_5_16_10.059416809308486_0.705778173474644.pt',16),\n",
    "    (\"Pinterest\",\"NCF\"): ('LXR_Pinterest_NCF_combined__neg-1.5pos_0_26_32_13.02585523498726_12.8447247971534.pt', 32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2c01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "num_features = num_items_dict[data_name]\n",
    "\n",
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]\n",
    "\n",
    "lxr_path = LXR_checkpoint_dict[(data_name,recommender_name)][0]\n",
    "lxr_dim = LXR_checkpoint_dict[(data_name,recommender_name)][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a6b87",
   "metadata": {},
   "source": [
    "## Data and baselines imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b88a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "with open(Path(files_path,f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f)\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()\n",
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f572bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'jaccard_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "    jaccard_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b5d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'cosine_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "    cosine_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cc86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b9348-ad75-4e2f-8b31-75748a39255b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "    item_to_cluster = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34114bbf-0762-4a56-9f27-4a616af8a27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'shap_values_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "    shap_values= pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b741d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(num_items):\n",
    "    for j in range(i, num_items):\n",
    "        jaccard_dict[(j,i)]= jaccard_dict[(i,j)]\n",
    "        cosine_dict[(j,i)]= cosine_dict[(i,j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826d25b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pop_array = np.zeros(len(pop_dict))\n",
    "for key, value in pop_dict.items():\n",
    "    pop_array[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5e9c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "           'num_features': num_items, \n",
    "            'demographic':False,\n",
    "          'pop_array':pop_array,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2db85e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da5589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.baselines_functions import *\n",
    "importlib.reload(ipynb.fs.defs.baselines_functions)\n",
    "from ipynb.fs.defs.baselines_functions import *\n",
    "\n",
    "lime = LimeBase(distance_to_proximity)\n",
    "\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63243da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recommender = load_recommender(data_name, hidden_dim, checkpoints_path, recommender_path, **kw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96048f75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baselines functions\n",
    "### Every function produces explanations for a designated baseline, resulting in a dictionary that maps items from the user's history to their explanation scores based on that baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950130f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cosine based similarities between users and items\n",
    "def find_cosine_mask(x, item_id, item_cosine):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_cosine_dict = {}\n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            if (i,item_id) in item_cosine:\n",
    "                item_cosine_dict[i]=item_cosine[(i,item_id)]\n",
    "            else:\n",
    "                item_cosine_dict[i]=0\n",
    "\n",
    "    return item_cosine_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fb4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lime_mask(x, item_id, min_pert, max_pert, num_of_perturbations, kernel_func, feature_selection, recommender, num_samples=10, method = 'POS', **kw_dict):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    lime.kernel_fn = kernel_func\n",
    "    neighborhood_data, neighborhood_labels, distances, item_id = get_lime_args(user_hist, item_id, recommender, all_items_tensor, min_pert = min_pert, max_pert = max_pert, num_of_perturbations = num_of_perturbations, seed = item_id, **kw_dict)\n",
    "    if method=='POS':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_samples, feature_selection, pos_neg='POS')\n",
    "    if method=='NEG':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_samples, feature_selection ,pos_neg='NEG')\n",
    "        \n",
    "    return most_pop_items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8194a-b8f3-4c3b-a111-0c73031318a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lire_mask(x, item_id, num_of_perturbations, kernel_func, feature_selection, recommender, proba=0.1, method = 'POS', **kw_dict):\n",
    "    user_hist = x \n",
    "    user_hist[item_id] = 0 # remove the positive item we want to explain from the user history\n",
    "    lime.kernel_fn = kernel_func\n",
    "    neighborhood_data, neighborhood_labels, distances, item_id = get_lire_args(user_hist, item_id, recommender, all_items_tensor, train_array, num_of_perturbations = num_of_perturbations, seed = item_id, proba=0.1, **kw_dict)\n",
    "    if method=='POS':\n",
    "        most_pop_items = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_of_perturbations, feature_selection, pos_neg='POS')\n",
    "    \n",
    "    return most_pop_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f7a42-6312-4394-96df-02d00bef793a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_deep_shap_mask(user_tensor, item_id, explainer):\n",
    "    # Reshape user_tensor to be 2D\n",
    "    if user_tensor.dim() == 1:\n",
    "        user_tensor = user_tensor.unsqueeze(0)\n",
    "    user_tensor = user_tensor.float().to(device).requires_grad_(True)\n",
    "    shap_values = explainer.shap_values(user_tensor)[item_id][0] #get deep shap values\n",
    "    \n",
    "    shap_value_dict = {}\n",
    "    for i, shap_value in enumerate(shap_values):  # Iterate over the SHAP values\n",
    "        if i != item_id:  # Exclude the item we want to explain\n",
    "            shap_value_dict[i] = shap_value.item() # Convert tensor to Python scalar and add to dictionary\n",
    "        else:\n",
    "            shap_value_dict[i] = 0  # Set the value to 0 for the item we are explaining\n",
    "\n",
    "    return shap_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778184b0-ff25-4cbb-ad98-e506d0f83565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_shapley_mask(user_tensor, user_id, model, shap_values, item_to_cluster):\n",
    "    item_shap = {}\n",
    "    shapley_values = shap_values[shap_values[:, 0].astype(int) == user_id][:,1:]\n",
    "    user_vector = user_tensor.cpu().detach().numpy().astype(int)\n",
    "\n",
    "    for i in np.where(user_vector.astype(int) == 1)[0]:\n",
    "        items_cluster = item_to_cluster[i]\n",
    "        item_shap[i] = shapley_values.T[int(items_cluster)][0]\n",
    "\n",
    "    return item_shap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a35c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_accent_mask(user_tensor, user_id, item_tensor, item_id, recommender_model, top_k):\n",
    "   \n",
    "    items_accent = defaultdict(float)\n",
    "    factor = top_k - 1\n",
    "    user_accent_hist = user_tensor.cpu().detach().numpy().astype(int)\n",
    "\n",
    "    #Get topk items\n",
    "    sorted_indices = list(get_top_k(user_tensor, user_tensor, recommender_model, **kw_dict).keys())\n",
    "    \n",
    "    if top_k == 1:\n",
    "        # When k=1, return the index of the first maximum value\n",
    "        top_k_indices = [sorted_indices[0]]\n",
    "    else:\n",
    "        top_k_indices = sorted_indices[:top_k]\n",
    "   \n",
    "\n",
    "    for iteration, item_k_id in enumerate(top_k_indices):\n",
    "\n",
    "        # Set topk items to 0 in the user's history\n",
    "        user_accent_hist[item_k_id] = 0\n",
    "        user_tensor = torch.FloatTensor(user_accent_hist).to(device)\n",
    "       \n",
    "        item_vector = items_array[item_k_id]\n",
    "        item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "              \n",
    "        # Check influence of the items in the history on this specific item in topk\n",
    "        fia_dict = find_fia_mask(user_tensor, item_tensor, item_k_id, recommender_model)\n",
    "         \n",
    "        # Sum up all differences between influence on top1 and other topk values\n",
    "        if not iteration:\n",
    "            for key in fia_dict.keys():\n",
    "                items_accent[key] *= factor\n",
    "        else:\n",
    "            for key in fia_dict.keys():\n",
    "                items_accent[key] -= fia_dict[key]\n",
    "       \n",
    "    for key in items_accent.keys():\n",
    "        items_accent[key] *= -1    \n",
    "\n",
    "    return items_accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f6e2d-e54b-44d4-b3f9-8abd3cae9142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lxr_mask(x, item_tensor, explainer):\n",
    "    user_hist = x\n",
    "    expl_scores = explainer(user_hist, item_tensor)\n",
    "    x_masked = user_hist*expl_scores\n",
    "    item_sim_dict = {}\n",
    "    for i,j in enumerate(x_masked!=0):\n",
    "        if j:\n",
    "            item_sim_dict[i]=x_masked[i] \n",
    "        \n",
    "    return item_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c2815b-6603-43ff-8fec-1226357600e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Explainer(nn.Module):\n",
    "    def __init__(self, user_size, item_size, hidden_size):\n",
    "        super(Explainer, self).__init__()\n",
    "        \n",
    "        self.users_fc = nn.Linear(in_features = user_size, out_features=hidden_size).to(device)\n",
    "        self.items_fc = nn.Linear(in_features = item_size, out_features=hidden_size).to(device)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features = hidden_size*2, out_features=hidden_size).to(device),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features = hidden_size, out_features=user_size).to(device),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, user_tensor, item_tensor):\n",
    "        user_output = self.users_fc(user_tensor.float())\n",
    "        item_output = self.items_fc(item_tensor.float())\n",
    "        combined_output = torch.cat((user_output, item_output), dim=-1)\n",
    "        expl_scores = self.bottleneck(combined_output).to(device)\n",
    "\n",
    "        return expl_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8fbb8-e866-4771-9cfb-c67ba007c3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_explainer(fine_tuning=False, lambda_pos=None, lambda_neg=None, alpha=None):\n",
    "    explainer = Explainer(num_features, num_items, lxr_dim)\n",
    "    lxr_checkpoint = torch.load(Path(checkpoints_path, lxr_path))\n",
    "    explainer.load_state_dict(lxr_checkpoint)\n",
    "    explainer.eval()\n",
    "    for param in explainer.parameters():\n",
    "        param.requires_grad= False\n",
    "    return explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb094e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5cdcc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender_model, user_id = None, mask_type = None, explainer=None):\n",
    "    '''\n",
    "    This function invokes various explanation functions\n",
    "    and returns a dictionary of explanations, sorted by their scores.\n",
    "    '''\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "\n",
    "    if mask_type == 'lime':\n",
    "        POS_sim_items = find_lime_mask(user_vector, item_id, 50, 100, 150, distance_to_proximity,'highest_weights', recommender_model, num_samples=user_hist_size, **kw_dict)\n",
    "    elif mask_type == 'lire':\n",
    "        POS_sim_items = find_lire_mask(user_vector, item_id, user_hist_size, distance_to_proximity, 'highest_weights', recommender_model,proba = 0.1, **kw_dict)\n",
    "    else:\n",
    "        if mask_type == 'cosine':\n",
    "            sim_items = find_cosine_mask(user_tensor, item_id, cosine_dict)\n",
    "        elif mask_type == 'shap':\n",
    "            sim_items = find_shapley_mask(user_tensor, user_id, recommender_model, shap_values, item_to_cluster)    \n",
    "        elif mask_type == 'deep_shap':\n",
    "            user_tensor = user_tensor.float().to(device).requires_grad_(True)\n",
    "            sim_items = find_deep_shap_mask(user_tensor, item_id, explainer)\n",
    "        elif mask_type == 'accent':\n",
    "            sim_items = find_accent_mask(user_tensor, user_id, item_tensor, item_id, recommender_model, 5)\n",
    "        elif mask_type == 'lxr':\n",
    "            explainer = load_explainer(False)\n",
    "            sim_items = find_lxr_mask(user_tensor, item_tensor, explainer)\n",
    "        POS_sim_items = list(sorted(sim_items.items(), key=lambda item: item[1],reverse=True))[0:user_hist_size]\n",
    "        \n",
    "    return POS_sim_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132628b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_dictionaries = True # if it is the first time generating the explanations - assing \"True\"\n",
    "\n",
    "include_deep_shap = True # if you want to create an explantion of the deep shap baseline\n",
    "\n",
    "if include_deep_shap: # create the explainer\n",
    "    subset_indices = np.random.choice(train_array.shape[0], size=10, replace=False)\n",
    "    background_data = train_array[subset_indices]\n",
    "    background_tensor = torch.FloatTensor(background_data).requires_grad_(True).to(device)\n",
    "    all_items_tensor = all_items_tensor.float().to(device).requires_grad_(True)\n",
    "    if recommender_name == \"MLP\":\n",
    "        model = MLPWrapper(recommender, all_items_tensor)\n",
    "    elif recommender_name == \"NCF\":\n",
    "        model = NCFWrapper(recommender, all_items_tensor)\n",
    "    else: # recommender_name == \"VAE\"\n",
    "        model = VAEWrapper(recommender)\n",
    "    deep_shap_explainer = shap.DeepExplainer(model, background_tensor)\n",
    "\n",
    "    \n",
    "    \n",
    "if create_dictionaries:\n",
    "    torch.cuda.empty_cache()\n",
    "    recommender.eval() # Evaluate the model on the test set\n",
    "\n",
    "    cosine_expl_dict = {}\n",
    "    lime_expl_dict = {}\n",
    "    lire_expl_dict = {}\n",
    "    accent_expl_dict = {}\n",
    "    shap_expl_dict = {}\n",
    "    deep_shap_expl_dict = {}\n",
    "    lxr_expl_dict = {}\n",
    "\n",
    "    for i in range(test_array.shape[0]):\n",
    "    #for i in range(3):\n",
    "        if i%500 == 0:\n",
    "            print(i)\n",
    "        start_time = time.time()\n",
    "        user_vector = test_array[i]\n",
    "        user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "        user_id = int(test_data.index[i])\n",
    "\n",
    "        item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "        item_vector =  items_array[item_id]\n",
    "        item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "\n",
    "        user_vector[item_id] = 0\n",
    "        user_tensor[item_id] = 0\n",
    "\n",
    "        recommender.to(device)\n",
    "\n",
    "        cosine_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'cosine')\n",
    "        lime_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'lime')\n",
    "        lire_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'lire')\n",
    "        accent_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'accent')\n",
    "        shap_expl_dict[user_id] = single_user_expl(user_vector, user_tensor,item_id, item_tensor, num_items, recommender, mask_type= 'shap',user_id = user_id)\n",
    "        deep_shap_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, all_items_tensor, num_items, recommender, mask_type='deep_shap', explainer=deep_shap_explainer)\n",
    "        lxr_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'lxr')\n",
    "\n",
    "\n",
    "    with open(Path(files_path,f'{recommender_name}_cosine_expl_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(cosine_expl_dict, handle)\n",
    "\n",
    "    with open(Path(files_path,f'{recommender_name}_lime_expl_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(lime_expl_dict, handle)\n",
    "\n",
    "    with open(Path(files_path,f'{recommender_name}_lire_expl_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(lire_expl_dict, handle)\n",
    "\n",
    "    with open(Path(files_path,f'{recommender_name}_accent_expl_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(accent_expl_dict, handle) \n",
    "\n",
    "    with open(Path(files_path,f'{recommender_name}_shap_expl_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(shap_expl_dict, handle)\n",
    "\n",
    "    with open(Path(files_path,f'{recommender_name}_deep_shap_expl_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(deep_shap_expl_dict, handle)\n",
    "\n",
    "    with open(Path(files_path,f'{recommender_name}_lxr_expl_dict.pkl'), 'wb') as handle:\n",
    "        pickle.dump(lxr_expl_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8febc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_one_expl_type(expl_name):\n",
    "    '''\n",
    "    This function aggregates explanations for all test users\n",
    "    and computes the average metric values across the entire test set.\n",
    "    '''\n",
    "    \n",
    "    print(f' ============ Start explaining {data_name} {recommender_name} by {expl_name} ============')\n",
    "    with open(Path(files_path,f'{recommender_name}_{expl_name}_expl_dict.pkl'), 'rb') as handle:\n",
    "        expl_dict = pickle.load(handle)\n",
    "    recommender.eval()     # Evaluate the model on the test set\n",
    "\n",
    "    num_of_bins = 11\n",
    "    \n",
    "    users_DEL = np.zeros(num_of_bins)\n",
    "    users_INS = np.zeros(num_of_bins)\n",
    "    NDCG = np.zeros(num_of_bins)\n",
    "    POS_at_5 = np.zeros(num_of_bins)\n",
    "    POS_at_10 = np.zeros(num_of_bins)\n",
    "    POS_at_20 = np.zeros(num_of_bins)\n",
    "\n",
    "    num_of_bins = 10\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(test_array.shape[0]):\n",
    "            start_time = time.time()\n",
    "            user_vector = test_array[i]\n",
    "            user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "            user_id = int(test_data.index[i])\n",
    "\n",
    "            item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "            item_vector =  items_array[item_id]\n",
    "            item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "            user_vector[item_id] = 0\n",
    "            user_tensor[item_id] = 0\n",
    "\n",
    "            user_expl = expl_dict[user_id]\n",
    "            res = single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender, user_expl, **kw_dict)\n",
    "            \n",
    "            users_DEL += res[0]\n",
    "            users_INS += res[1]\n",
    "            NDCG += res[2]\n",
    "            POS_at_5 += res[3]\n",
    "            POS_at_10 += res[4]\n",
    "            POS_at_20 += res[5]\n",
    "        \n",
    "\n",
    "    a = i+1\n",
    "    \n",
    "    file_mode = 'a' if os.path.exists(new_file_name) else 'w'\n",
    "    with open(new_file_name, file_mode) as file:\n",
    "        file.write(f' ============ This stats are for {data_name} dataset ============\\n')\n",
    "        file.write(f' ============ & for the recommender {recommender_name} ============\\n')\n",
    "        file.write(f' ============ {expl_name} ============\\n')\n",
    "        file.write(f\"{np.mean(users_DEL)/a}, {np.mean(users_INS)/a}, {np.mean(NDCG)/a}, {np.mean(POS_at_5)/a}, {np.mean(POS_at_10)/a}, {np.mean(POS_at_20)/a}\\n\")\n",
    "        file.write(f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d66300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expl_names_list = ['cosine', 'accent', 'lime', 'lire', 'shap', 'deep_shap', 'lxr'] # specify the names of the baselines for which you wish to calculate the metrics values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c4d29",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for expl_name in expl_names_list:\n",
    "    eval_one_expl_type(expl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a317a-b94e-4f27-b3a0-ed1ed79a493b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561aca8e-59f7-4f80-a5f4-a94ecab58d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18831b05",
   "metadata": {},
   "source": [
    "### This notebook produces the metrics for a specific recommendation system and dataset for all the baselines.\n",
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160299a9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:46.977173Z",
     "iopub.status.busy": "2024-09-25T07:20:46.976741Z",
     "iopub.status.idle": "2024-09-25T07:20:49.042264Z",
     "shell.execute_reply": "2024-09-25T07:20:49.041412Z",
     "shell.execute_reply.started": "2024-09-25T07:20:46.977132Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import ipynb\n",
    "import importlib\n",
    "import sys\n",
    "import shap\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59163763",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:49.043948Z",
     "iopub.status.busy": "2024-09-25T07:20:49.043611Z",
     "iopub.status.idle": "2024-09-25T07:20:49.054661Z",
     "shell.execute_reply": "2024-09-25T07:20:49.053933Z",
     "shell.execute_reply.started": "2024-09-25T07:20:49.043929Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"NCF\" ### Can be MLP, VAE, NCF\n",
    "\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(export_dir.parent, DP_DIR)\n",
    "checkpoints_path = Path(export_dir.parent, \"check\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56467a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:49.055543Z",
     "iopub.status.busy": "2024-09-25T07:20:49.055386Z",
     "iopub.status.idle": "2024-09-25T07:20:49.063819Z",
     "shell.execute_reply": "2024-09-25T07:20:49.063149Z",
     "shell.execute_reply.started": "2024-09-25T07:20:49.055527Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}\n",
    "\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\"),}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a2c01f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:49.064822Z",
     "iopub.status.busy": "2024-09-25T07:20:49.064583Z",
     "iopub.status.idle": "2024-09-25T07:20:49.068762Z",
     "shell.execute_reply": "2024-09-25T07:20:49.068114Z",
     "shell.execute_reply.started": "2024-09-25T07:20:49.064801Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "\n",
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a6b87",
   "metadata": {},
   "source": [
    "## Data and baselines imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1b88a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:49.070881Z",
     "iopub.status.busy": "2024-09-25T07:20:49.070579Z",
     "iopub.status.idle": "2024-09-25T07:20:51.434806Z",
     "shell.execute_reply": "2024-09-25T07:20:51.433985Z",
     "shell.execute_reply.started": "2024-09-25T07:20:49.070859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "with open(Path(files_path,f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f)\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()\n",
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f572bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:51.435692Z",
     "iopub.status.busy": "2024-09-25T07:20:51.435535Z",
     "iopub.status.idle": "2024-09-25T07:20:55.203274Z",
     "shell.execute_reply": "2024-09-25T07:20:55.202416Z",
     "shell.execute_reply.started": "2024-09-25T07:20:51.435676Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'jaccard_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "    jaccard_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d1b5d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.204490Z",
     "iopub.status.busy": "2024-09-25T07:20:55.204224Z",
     "iopub.status.idle": "2024-09-25T07:20:55.207981Z",
     "shell.execute_reply": "2024-09-25T07:20:55.207017Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.204472Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'cosine_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "    cosine_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e47cc86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.209676Z",
     "iopub.status.busy": "2024-09-25T07:20:55.209256Z",
     "iopub.status.idle": "2024-09-25T07:20:55.213466Z",
     "shell.execute_reply": "2024-09-25T07:20:55.212377Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.209641Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9b9348-ad75-4e2f-8b31-75748a39255b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.215571Z",
     "iopub.status.busy": "2024-09-25T07:20:55.214885Z",
     "iopub.status.idle": "2024-09-25T07:20:55.218988Z",
     "shell.execute_reply": "2024-09-25T07:20:55.218147Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.215529Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "    item_to_cluster = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34114bbf-0762-4a56-9f27-4a616af8a27b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.220831Z",
     "iopub.status.busy": "2024-09-25T07:20:55.220395Z",
     "iopub.status.idle": "2024-09-25T07:20:55.224553Z",
     "shell.execute_reply": "2024-09-25T07:20:55.223675Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.220797Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(Path(files_path, f'shap_values_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "    shap_values= pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b741d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.225964Z",
     "iopub.status.busy": "2024-09-25T07:20:55.225472Z",
     "iopub.status.idle": "2024-09-25T07:20:55.228943Z",
     "shell.execute_reply": "2024-09-25T07:20:55.228303Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.225939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(num_items):\n",
    "    for j in range(i, num_items):\n",
    "        jaccard_dict[(j,i)]= jaccard_dict[(i,j)]\n",
    "        cosine_dict[(j,i)]= cosine_dict[(i,j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a826d25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.230104Z",
     "iopub.status.busy": "2024-09-25T07:20:55.229895Z",
     "iopub.status.idle": "2024-09-25T07:20:55.235096Z",
     "shell.execute_reply": "2024-09-25T07:20:55.234472Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.230083Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pop_array = np.zeros(len(pop_dict))\n",
    "for key, value in pop_dict.items():\n",
    "    pop_array[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df5e9c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.236353Z",
     "iopub.status.busy": "2024-09-25T07:20:55.236044Z",
     "iopub.status.idle": "2024-09-25T07:20:55.240573Z",
     "shell.execute_reply": "2024-09-25T07:20:55.239675Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.236330Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "           'num_features': num_items, \n",
    "            'demographic':False,\n",
    "          'pop_array':pop_array,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2db85e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09da5589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.244347Z",
     "iopub.status.busy": "2024-09-25T07:20:55.244041Z",
     "iopub.status.idle": "2024-09-25T07:20:55.326619Z",
     "shell.execute_reply": "2024-09-25T07:20:55.325748Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.244324Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.baselines_functions import *\n",
    "importlib.reload(ipynb.fs.defs.baselines_functions)\n",
    "from ipynb.fs.defs.baselines_functions import *\n",
    "\n",
    "lime = LimeBase(distance_to_proximity)\n",
    "\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63243da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.328580Z",
     "iopub.status.busy": "2024-09-25T07:20:55.328001Z",
     "iopub.status.idle": "2024-09-25T07:20:55.376175Z",
     "shell.execute_reply": "2024-09-25T07:20:55.375198Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.328536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "recommender = load_recommender(data_name, hidden_dim, checkpoints_path, recommender_path, **kw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96048f75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baselines functions\n",
    "### Every function produces explanations for a designated baseline, resulting in a dictionary that maps items from the user's history to their explanation scores based on that baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25797d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.386422Z",
     "iopub.status.busy": "2024-09-25T07:20:55.386088Z",
     "iopub.status.idle": "2024-09-25T07:20:55.391833Z",
     "shell.execute_reply": "2024-09-25T07:20:55.390820Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.386399Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#User based similarities using Jaccard\n",
    "def find_jaccard_mask(x, item_id, user_based_Jaccard_sim):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_jaccard_dict = {}\n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            if (i,item_id) in user_based_Jaccard_sim:\n",
    "                item_jaccard_dict[i]=user_based_Jaccard_sim[(i,item_id)] # add Jaccard similarity between items\n",
    "            else:\n",
    "                item_jaccard_dict[i] = 0            \n",
    "\n",
    "    return item_jaccard_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "950130f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.393283Z",
     "iopub.status.busy": "2024-09-25T07:20:55.392848Z",
     "iopub.status.idle": "2024-09-25T07:20:55.398448Z",
     "shell.execute_reply": "2024-09-25T07:20:55.397449Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.393259Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cosine based similarities between users and items\n",
    "def find_cosine_mask(x, item_id, item_cosine):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_cosine_dict = {}\n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            if (i,item_id) in item_cosine:\n",
    "                item_cosine_dict[i]=item_cosine[(i,item_id)]\n",
    "            else:\n",
    "                item_cosine_dict[i]=0\n",
    "\n",
    "    return item_cosine_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e9fb4fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.399522Z",
     "iopub.status.busy": "2024-09-25T07:20:55.399320Z",
     "iopub.status.idle": "2024-09-25T07:20:55.405516Z",
     "shell.execute_reply": "2024-09-25T07:20:55.404750Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.399502Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lime_mask(x, item_id, min_pert, max_pert, num_of_perturbations, kernel_func, feature_selection, recommender, num_samples=10, method = 'POS', **kw_dict):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    lime.kernel_fn = kernel_func\n",
    "    neighborhood_data, neighborhood_labels, distances, item_id = get_lime_args(user_hist, item_id, recommender, all_items_tensor, min_pert = min_pert, max_pert = max_pert, num_of_perturbations = num_of_perturbations, seed = item_id, **kw_dict)\n",
    "    if method=='POS':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_samples, feature_selection, pos_neg='POS')\n",
    "    if method=='NEG':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_samples, feature_selection ,pos_neg='NEG')\n",
    "        \n",
    "    return most_pop_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf8194a-b8f3-4c3b-a111-0c73031318a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.406664Z",
     "iopub.status.busy": "2024-09-25T07:20:55.406370Z",
     "iopub.status.idle": "2024-09-25T07:20:55.412173Z",
     "shell.execute_reply": "2024-09-25T07:20:55.411395Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.406642Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_lire_mask(x, item_id, num_of_perturbations, kernel_func, feature_selection, recommender, proba=0.1, method = 'POS', **kw_dict):\n",
    "    \n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    lime.kernel_fn = kernel_func\n",
    "    neighborhood_data, neighborhood_labels, distances, item_id = get_lire_args(user_hist, item_id, recommender, all_items_tensor, train_array, num_of_perturbations = num_of_perturbations, seed = item_id, proba=0.1, **kw_dict)\n",
    "    if method=='POS':\n",
    "        most_pop_items = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_of_perturbations, feature_selection, pos_neg='POS')\n",
    "    \n",
    "    return most_pop_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "778184b0-ff25-4cbb-ad98-e506d0f83565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.421248Z",
     "iopub.status.busy": "2024-09-25T07:20:55.420652Z",
     "iopub.status.idle": "2024-09-25T07:20:55.426349Z",
     "shell.execute_reply": "2024-09-25T07:20:55.425452Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.421223Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_shapley_mask(user_tensor, user_id, model, shap_values, item_to_cluster):\n",
    "    item_shap = {}\n",
    "    shapley_values = shap_values[shap_values[:, 0].astype(int) == user_id][:,1:]\n",
    "    user_vector = user_tensor.cpu().detach().numpy().astype(int)\n",
    "\n",
    "    for i in np.where(user_vector.astype(int) == 1)[0]:\n",
    "        items_cluster = item_to_cluster[i]\n",
    "        item_shap[i] = shapley_values.T[int(items_cluster)][0]\n",
    "\n",
    "    return item_shap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69a35c9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.427422Z",
     "iopub.status.busy": "2024-09-25T07:20:55.427220Z",
     "iopub.status.idle": "2024-09-25T07:20:55.435875Z",
     "shell.execute_reply": "2024-09-25T07:20:55.434981Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.427401Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_accent_mask(user_tensor, user_id, item_tensor, item_id, recommender_model, top_k):\n",
    "   \n",
    "    items_accent = defaultdict(float)\n",
    "    factor = top_k - 1\n",
    "    user_accent_hist = user_tensor.cpu().detach().numpy().astype(int)\n",
    "\n",
    "    #Get topk items\n",
    "    sorted_indices = list(get_top_k(user_tensor, user_tensor, recommender_model, **kw_dict).keys())\n",
    "    \n",
    "    if top_k == 1:\n",
    "        # When k=1, return the index of the first maximum value\n",
    "        top_k_indices = [sorted_indices[0]]\n",
    "    else:\n",
    "        top_k_indices = sorted_indices[:top_k]\n",
    "   \n",
    "\n",
    "    for iteration, item_k_id in enumerate(top_k_indices):\n",
    "\n",
    "        # Set topk items to 0 in the user's history\n",
    "        user_accent_hist[item_k_id] = 0\n",
    "        user_tensor = torch.FloatTensor(user_accent_hist).to(device)\n",
    "       \n",
    "        item_vector = items_array[item_k_id]\n",
    "        item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "              \n",
    "        # Check influence of the items in the history on this specific item in topk\n",
    "        fia_dict = find_fia_mask(user_tensor, item_tensor, item_k_id, recommender_model)\n",
    "         \n",
    "        # Sum up all differences between influence on top1 and other topk values\n",
    "        if not iteration:\n",
    "            for key in fia_dict.keys():\n",
    "                items_accent[key] *= factor\n",
    "        else:\n",
    "            for key in fia_dict.keys():\n",
    "                items_accent[key] -= fia_dict[key]\n",
    "       \n",
    "    for key in items_accent.keys():\n",
    "        items_accent[key] *= -1    \n",
    "\n",
    "    return items_accent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c81d42a-3c88-43e0-a784-ae2028c4e215",
   "metadata": {},
   "source": [
    "#### LXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51072528-e490-40e3-8e22-d41cc6bf1f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.437407Z",
     "iopub.status.busy": "2024-09-25T07:20:55.436824Z",
     "iopub.status.idle": "2024-09-25T07:20:55.441776Z",
     "shell.execute_reply": "2024-09-25T07:20:55.440878Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.437381Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_lxr_mask(x, item_tensor, explainer):\n",
    "    \n",
    "    user_hist = x\n",
    "    expl_scores = explainer(user_hist, item_tensor)\n",
    "    x_masked = user_hist*expl_scores\n",
    "    item_sim_dict = {}\n",
    "    for i,j in enumerate(x_masked!=0):\n",
    "        if j:\n",
    "            item_sim_dict[i]=x_masked[i] \n",
    "        \n",
    "    return item_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e20c9af3-950c-4ee8-9724-3e3bbe7d003f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.442838Z",
     "iopub.status.busy": "2024-09-25T07:20:55.442638Z",
     "iopub.status.idle": "2024-09-25T07:20:55.450362Z",
     "shell.execute_reply": "2024-09-25T07:20:55.449466Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.442818Z"
    }
   },
   "outputs": [],
   "source": [
    "class Explainer(nn.Module):\n",
    "    def __init__(self, user_size, item_size, hidden_size):\n",
    "        super(Explainer, self).__init__()\n",
    "        \n",
    "        self.users_fc = nn.Linear(in_features = user_size, out_features=hidden_size).to(device)\n",
    "        self.items_fc = nn.Linear(in_features = item_size, out_features=hidden_size).to(device)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features = hidden_size*2, out_features=hidden_size).to(device),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features = hidden_size, out_features=user_size).to(device),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, user_tensor, item_tensor):\n",
    "        user_output = self.users_fc(user_tensor.float())\n",
    "        item_output = self.items_fc(item_tensor.float())\n",
    "        combined_output = torch.cat((user_output, item_output), dim=-1)\n",
    "        expl_scores = self.bottleneck(combined_output).to(device)\n",
    "\n",
    "        return expl_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23b0d5e6-e91b-4888-8922-91983442dfd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.451923Z",
     "iopub.status.busy": "2024-09-25T07:20:55.451295Z",
     "iopub.status.idle": "2024-09-25T07:20:55.456472Z",
     "shell.execute_reply": "2024-09-25T07:20:55.455570Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.451898Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_explainer(fine_tuning=False, lambda_pos=None, lambda_neg=None, alpha=None):\n",
    "    explainer = Explainer(num_features, num_items, lxr_dim)\n",
    "    lxr_checkpoint = torch.load(Path(checkpoints_path, lxr_path))\n",
    "    explainer.load_state_dict(lxr_checkpoint)\n",
    "    explainer.eval()\n",
    "    for param in explainer.parameters():\n",
    "        param.requires_grad= False\n",
    "    return explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea8599e1-3a7d-488a-adec-15edac6ba901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.457866Z",
     "iopub.status.busy": "2024-09-25T07:20:55.457421Z",
     "iopub.status.idle": "2024-09-25T07:20:55.466686Z",
     "shell.execute_reply": "2024-09-25T07:20:55.465858Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.457842Z"
    }
   },
   "outputs": [],
   "source": [
    "class LXR_loss(nn.Module):\n",
    "    def __init__(self, lambda_pos, lambda_neg, alpha):\n",
    "        super(LXR_loss, self).__init__()\n",
    "        \n",
    "        self.lambda_pos = lambda_pos\n",
    "        self.lambda_neg = lambda_neg\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        \n",
    "    def forward(self, user_tensors, items_tensors, items_ids, pos_masks):\n",
    "        neg_masks = torch.sub(torch.ones_like(pos_masks), pos_masks)\n",
    "        x_masked_pos = user_tensors * pos_masks\n",
    "        x_masked_neg = user_tensors * neg_masks\n",
    "        if output_type=='single':\n",
    "            x_masked_res_pos = recommender_run(x_masked_pos, recommender, items_tensors, item_id=items_ids, wanted_output = 'single', **kw_dict)\n",
    "            x_masked_res_neg = recommender_run(x_masked_neg, recommender, items_tensors, item_id=items_ids, wanted_output = 'single', **kw_dict)\n",
    "        else:\n",
    "            x_masked_res_pos_before = recommender_run(x_masked_pos, recommender, items_tensors, item_id=items_ids, wanted_output = 'vector', **kw_dict)\n",
    "            x_masked_res_neg_before = recommender_run(x_masked_neg, recommender, items_tensors, item_id=items_ids, wanted_output = 'vector', **kw_dict)\n",
    "            rows=torch.arange(len(items_ids))\n",
    "            x_masked_res_pos = x_masked_res_pos_before[rows, items_ids] \n",
    "            x_masked_res_neg = x_masked_res_neg_before[rows, items_ids] \n",
    "        \n",
    "            \n",
    "        pos_loss = -torch.mean(torch.log(x_masked_res_pos))\n",
    "        neg_loss = torch.mean(torch.log(x_masked_res_neg))\n",
    "        l1 = x_masked_pos[x_masked_pos>0].mean()\n",
    "        combined_loss = self.lambda_pos*pos_loss + self.lambda_neg*neg_loss + self.alpha*l1\n",
    "        return combined_loss, pos_loss, neg_loss, l1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb094e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad5cdcc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:20:55.467713Z",
     "iopub.status.busy": "2024-09-25T07:20:55.467469Z",
     "iopub.status.idle": "2024-09-25T07:20:55.474872Z",
     "shell.execute_reply": "2024-09-25T07:20:55.474083Z",
     "shell.execute_reply.started": "2024-09-25T07:20:55.467697Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender_model, user_id = None, mask_type = None):\n",
    "    '''\n",
    "    This function invokes various explanation functions\n",
    "    and returns a dictionary of explanations, sorted by their scores.\n",
    "    '''\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "\n",
    "    if mask_type == 'lime':\n",
    "        POS_sim_items = find_lime_mask(user_vector, item_id, 50, 100, 150, distance_to_proximity,'highest_weights', recommender_model, num_samples=user_hist_size, **kw_dict)\n",
    "    elif mask_type == 'lire':\n",
    "        POS_sim_items = find_lire_mask(user_vector, item_id, user_hist_size, distance_to_proximity,'highest_weights', recommender_model,proba = 0.1, **kw_dict)\n",
    "    else:\n",
    "        if mask_type == 'jaccard':\n",
    "            sim_items = find_jaccard_mask(user_tensor, item_id, jaccard_dict)\n",
    "        elif mask_type == 'cosine':\n",
    "            sim_items = find_cosine_mask(user_tensor, item_id, cosine_dict)\n",
    "        elif mask_type == 'shap':\n",
    "            sim_items = find_shapley_mask(user_tensor, user_id, recommender_model, shap_values, item_to_cluster)\n",
    "        elif mask_type == 'accent':\n",
    "            sim_items = find_accent_mask(user_tensor, user_id, item_tensor, item_id, recommender_model, 5)\n",
    "        elif mask_type == 'lxr':\n",
    "            sim_items = find_lxr_mask(user_tensor, item_tensor)\n",
    "            \n",
    "        POS_sim_items = list(sorted(sim_items.items(), key=lambda item: item[1],reverse=True))[0:user_hist_size]\n",
    "        \n",
    "    return POS_sim_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4132628b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:23:15.247059Z",
     "iopub.status.busy": "2024-09-25T07:23:15.246644Z",
     "iopub.status.idle": "2024-09-25T07:30:34.806226Z",
     "shell.execute_reply": "2024-09-25T07:30:34.805206Z",
     "shell.execute_reply.started": "2024-09-25T07:23:15.247022Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "create_dictionaries = True # if it is the first time generating the explanations - assing \"True\"\n",
    "\n",
    "if create_dictionaries:\n",
    "    recommender.eval()\n",
    "    # Evaluate the model on the test set\n",
    "    \n",
    "    jaccard_expl_dict = {}\n",
    "    cosine_expl_dict = {}\n",
    "    lime_expl_dict = {}\n",
    "    lire_expl_dict = {}\n",
    "    accent_expl_dict = {}\n",
    "    shap_expl_dict = {}\n",
    "    deep_shap_expl_dict = {}\n",
    "    lxr_expl_dict = {}\n",
    "  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(test_array.shape[0]):\n",
    "        # for i in range(3):\n",
    "            if i%100 == 0:\n",
    "                print(f\" --------- User number: {i} ----------\")\n",
    "            start_time = time.time()\n",
    "            user_vector = test_array[i]\n",
    "            user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "            user_id = int(test_data.index[i])\n",
    "\n",
    "            item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "            item_vector =  items_array[item_id]\n",
    "            item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "\n",
    "            user_vector[item_id] = 0\n",
    "            user_tensor[item_id] = 0\n",
    "\n",
    "            recommender.to(device)\n",
    "\n",
    "            jaccard_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'jaccard')\n",
    "            cosine_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'cosine')\n",
    "            lime_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'lime')\n",
    "            lire_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'lire')\n",
    "            accent_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'accent')\n",
    "            shap_expl_dict[user_id] = single_user_expl(user_vector, user_tensor,item_id, item_tensor, num_items, recommender, mask_type= 'shap',user_id = user_id)\n",
    "            deep_shap_expl_dict[user_id] = single_user_expl(user_vector, user_tensor,item_id, item_tensor, num_items, recommender, mask_type= 'deep_shap')\n",
    "            lxr_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type= 'lxr')\n",
    "        \n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_jaccard_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(jaccard_expl_dict, handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_cosine_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(cosine_expl_dict, handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_lime_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(lime_expl_dict, handle)\n",
    "            \n",
    "        with open(Path(files_path,f'{recommender_name}_lire_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(lire_expl_dict, handle)\n",
    "            \n",
    "        with open(Path(files_path,f'{recommender_name}_accent_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(accent_expl_dict, handle) \n",
    "            \n",
    "        with open(Path(files_path,f'{recommender_name}_shap_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(shap_expl_dict, handle)\n",
    "        \n",
    "        with open(Path(files_path,f'{recommender_name}_deep_shap_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(deep_shap_expl_dict, handle)\n",
    "\n",
    "        with open(Path(files_path,f'{recommender_name}_lxr_expl_dict.pkl'), 'wb') as handle:\n",
    "            pickle.dump(lxr_expl_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afc8320a-a4df-487f-85b1-26fea4bd208b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:30:34.807693Z",
     "iopub.status.busy": "2024-09-25T07:30:34.807524Z",
     "iopub.status.idle": "2024-09-25T07:30:34.812119Z",
     "shell.execute_reply": "2024-09-25T07:30:34.811021Z",
     "shell.execute_reply.started": "2024-09-25T07:30:34.807676Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_file_name = \"ZZ_CHECK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12d8febc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:30:34.814611Z",
     "iopub.status.busy": "2024-09-25T07:30:34.813973Z",
     "iopub.status.idle": "2024-09-25T07:30:34.831887Z",
     "shell.execute_reply": "2024-09-25T07:30:34.830829Z",
     "shell.execute_reply.started": "2024-09-25T07:30:34.814564Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_one_expl_type(expl_name):\n",
    "    '''\n",
    "    This function aggregates explanations for all test users\n",
    "    and computes the average metric values across the entire test set.\n",
    "    '''\n",
    "    \n",
    "    print(f' ============ Start explaining {data_name} {recommender_name} by {expl_name} ============')\n",
    "    with open(Path(files_path,f'{recommender_name}_{expl_name}_expl_dict.pkl'), 'rb') as handle:\n",
    "        expl_dict = pickle.load(handle)\n",
    "    recommender.eval()\n",
    "    # Evaluate the model on the test set\n",
    "\n",
    "    num_of_bins = 11\n",
    "    \n",
    "    users_DEL = np.zeros(num_of_bins)\n",
    "    users_INS = np.zeros(num_of_bins)\n",
    "    reciprocal = np.zeros(num_of_bins)\n",
    "    NDCG = np.zeros(num_of_bins)\n",
    "    POS_at_1 = np.zeros(num_of_bins)\n",
    "    POS_at_5 = np.zeros(num_of_bins)\n",
    "    POS_at_10 = np.zeros(num_of_bins)\n",
    "    POS_at_20 = np.zeros(num_of_bins)\n",
    "    POS_at_50 = np.zeros(num_of_bins)\n",
    "    POS_at_100 = np.zeros(num_of_bins)\n",
    "    NEG_at_1 = np.zeros(num_of_bins)\n",
    "    NEG_at_5 = np.zeros(num_of_bins)\n",
    "    NEG_at_10 = np.zeros(num_of_bins)\n",
    "    NEG_at_20 = np.zeros(num_of_bins)\n",
    "    NEG_at_50 = np.zeros(num_of_bins)\n",
    "    NEG_at_100 = np.zeros(num_of_bins)\n",
    "    rank_at_1 = np.zeros(num_of_bins)\n",
    "    rank_at_5 = np.zeros(num_of_bins)\n",
    "    rank_at_10 = np.zeros(num_of_bins)\n",
    "    rank_at_20 = np.zeros(num_of_bins)\n",
    "    rank_at_50 = np.zeros(num_of_bins)\n",
    "    rank_at_100 = np.zeros(num_of_bins)\n",
    "\n",
    "    num_of_bins = 10\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(test_array.shape[0])\n",
    "        for i in range(test_array.shape[0]):\n",
    "        # for i in range(3):\n",
    "            start_time = time.time()\n",
    "            user_vector = test_array[i]\n",
    "            user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "            user_id = int(test_data.index[i])\n",
    "\n",
    "            item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "            item_vector =  items_array[item_id]\n",
    "            item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "            user_vector[item_id] = 0\n",
    "            user_tensor[item_id] = 0\n",
    "\n",
    "            user_expl = expl_dict[user_id]\n",
    "            res = single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender, user_expl, **kw_dict)\n",
    "            \n",
    "            users_DEL += res[0]\n",
    "            users_INS += res[1]\n",
    "            reciprocal += res[2]\n",
    "            NDCG += res[3]\n",
    "            POS_at_1 += res[4]\n",
    "            POS_at_5 += res[5]\n",
    "            POS_at_10 += res[6]\n",
    "            POS_at_20 += res[7]\n",
    "            POS_at_50 += res[8]\n",
    "            POS_at_100 += res[9]\n",
    "            NEG_at_1 += res[10]\n",
    "            NEG_at_5 += res[11]\n",
    "            NEG_at_10 += res[12]\n",
    "            NEG_at_20 += res[13]\n",
    "            NEG_at_50 += res[14]\n",
    "            NEG_at_100 += res[15]\n",
    "            rank_at_1 += res[16]\n",
    "            rank_at_5 += res[17]\n",
    "            rank_at_10 += res[18]\n",
    "            rank_at_20 += res[19]\n",
    "            rank_at_50 += res[20]\n",
    "            rank_at_100 += res[21]\n",
    "\n",
    "            if i%500 == 0:\n",
    "                print(i)\n",
    "\n",
    "    a = i+1\n",
    "    \n",
    "    file_mode = 'a' if os.path.exists(new_file_name) else 'w'\n",
    "    with open(new_file_name, file_mode) as file:\n",
    "        file.write(f' ============ This stats are for {data_name} dataset ============\\n')\n",
    "        file.write(f' ============ & for the recommender {recommender_name} ============\\n')\n",
    "        file.write(f' ============ {expl_name} ============\\n')\n",
    "        file.write(f\"{np.mean(users_DEL)/a}, {np.mean(users_INS)/a}, {np.mean(reciprocal)/a}, {np.mean(NDCG)/a}, {np.mean(POS_at_1)/a}, {np.mean(NEG_at_1)/a}, {np.mean(rank_at_1)/a}, {np.mean(POS_at_5)/a}, {np.mean(NEG_at_5)/a}, {np.mean(rank_at_5)/a}, {np.mean(POS_at_10)/a}, {np.mean(NEG_at_10)/a}, {np.mean(rank_at_10)/a}, {np.mean(POS_at_20)/a}, {np.mean(NEG_at_20)/a}, {np.mean(rank_at_20)/a}, {np.mean(POS_at_50)/a}, {np.mean(NEG_at_50)/a}, {np.mean(rank_at_50)/a}, {np.mean(POS_at_100)/a}, {np.mean(NEG_at_100)/a}, {np.mean(rank_at_100)/a}\\n\")\n",
    "        file.write(f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10d66300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:30:34.833482Z",
     "iopub.status.busy": "2024-09-25T07:30:34.833226Z",
     "iopub.status.idle": "2024-09-25T07:30:34.837553Z",
     "shell.execute_reply": "2024-09-25T07:30:34.836379Z",
     "shell.execute_reply.started": "2024-09-25T07:30:34.833466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "expl_names_list = ['jaccard', 'cosine', 'accent', 'lime', 'lire', 'fia', 'lxr'] # specify the names of the baselines for which you wish to calculate the metrics values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "056c4d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-25T07:30:34.839346Z",
     "iopub.status.busy": "2024-09-25T07:30:34.838791Z",
     "iopub.status.idle": "2024-09-25T07:39:26.281908Z",
     "shell.execute_reply": "2024-09-25T07:39:26.280726Z",
     "shell.execute_reply.started": "2024-09-25T07:30:34.839306Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ============ Start explaining ML1M NCF by lire ============\n",
      "1208\n",
      "0\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for expl_name in expl_names_list:\n",
    "    eval_one_expl_type(expl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a317a-b94e-4f27-b3a0-ed1ed79a493b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561aca8e-59f7-4f80-a5f4-a94ecab58d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
